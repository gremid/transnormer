{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EiDFQvLYjVlA"
      },
      "source": [
        "# A minimal example of my problems with training byT5\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_qZNxtjexA"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rVteV_8jjHvd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "import datasets              "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def models_identical(model1, model2) -> bool:\n",
        "    unequal_states = []\n",
        "    for (name_mo, params_mo), (name_mn, params_mn) in zip(model1.state_dict().items(), model2.state_dict().items()):\n",
        "        assert name_mo == name_mn\n",
        "        if not torch.equal(params_mo, params_mn):\n",
        "            unequal_states.append(name_mo)\n",
        "    return len(unequal_states) == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'model' in locals():\n",
        "    del model\n",
        "    \n",
        "if 'model_orig' in locals():\n",
        "    del model_orig\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TD9oc4Zjtl-u"
      },
      "outputs": [],
      "source": [
        "checkpoint_name = \"google/byt5-small\"\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = transformers.T5ForConditionalGeneration.from_pretrained(checkpoint_name).to(device)\n",
        "model_orig = transformers.T5ForConditionalGeneration.from_pretrained(checkpoint_name).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_6tQrYxoh8K",
        "outputId": "6cd679fe-3437-4059-ae52-d9cb033f2452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[105, 114, 114,  35, 101, 100, 117,   0,   0,   0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]), 'labels': tensor([[ 117,  100,  101,   35,  114,  114,  105, -100, -100, -100]])}\n",
            "{'input_ids': [105, 114, 114, 35, 101, 100, 117, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0], 'labels': [117, 100, 101, 35, 114, 114, 105, -100, -100, -100]}\n"
          ]
        }
      ],
      "source": [
        "train_data = {\"input_ids\" : torch.tensor([[105, 114, 114, 35, 101, 100, 117, 0, 0, 0]]), \n",
        "              \"attention_mask\" : torch.tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]) ,\n",
        "              \"labels\" : torch.tensor([[117, 100, 101, 35, 114, 114, 105, -100, -100, -100]])}\n",
        "# train_data = {k: v.to(device) for k, v in train_data.items()} # muss das Ã¼berhaupt?\n",
        "print(train_data)\n",
        "# convert to a Dataset object\n",
        "ds_train = datasets.Dataset.from_dict(train_data)\n",
        "print(ds_train[0])\n",
        "# evaluation data is just a copy of train_data\n",
        "ds_eval = ds_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mjYH01Aeoj9L"
      },
      "outputs": [],
      "source": [
        "epochs = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CbMnUxQjmkj7"
      },
      "outputs": [],
      "source": [
        "# mininal training arguments\n",
        "training_args = transformers.Seq2SeqTrainingArguments(\n",
        "    output_dir=\"test\",\n",
        "    predict_with_generate=True,\n",
        "    # evaluation_strategy = \"steps\",\n",
        "    # fp16=True, ####### Hier spielt die Musik \n",
        "    eval_steps=100,\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6wjXcsZUjVU_"
      },
      "outputs": [],
      "source": [
        "# initialize the trainer\n",
        "trainer = transformers.Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=ds_train,\n",
        "    eval_dataset=ds_eval,\n",
        ")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tdmDVgxpkDqB"
      },
      "source": [
        "# A. With `Trainer.train()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "wqUyHcawkDyf",
        "outputId": "b9c7f960-c457-451c-a588-cacc1bceb1ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bracke/miniconda3/envs/gpu-venv-transnormer/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 1\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 1\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 200\n",
            "  Number of trainable parameters = 299637760\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [200/200 00:32, Epoch 200/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=200, training_loss=3.6698907470703124, metrics={'train_runtime': 32.3615, 'train_samples_per_second': 6.18, 'train_steps_per_second': 6.18, 'total_flos': 3588865536000.0, 'train_loss': 3.6698907470703124, 'epoch': 200.0})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G_usUyvndyU",
        "outputId": "70932d42-3102-496e-be58-a2bd055fe15d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Untrained model and trained model are the same: False\n",
            "Untrained model and trained model are the same: False\n"
          ]
        }
      ],
      "source": [
        "# Check whether models are identical\n",
        "print(\"Untrained model and trained model are the same:\", \n",
        "    models_identical(model_orig, model)\n",
        "    )\n",
        "\n",
        "print(\"Untrained model and trained model are the same:\", \n",
        "    models_identical(model_orig, trainer.model)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpFMzsxKueKm",
        "outputId": "303a796c-13d9-4f3d-8f7a-3654fbbde3a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and trainer.model are the same: True\n"
          ]
        }
      ],
      "source": [
        "print(\"Model and trainer.model are the same:\", \n",
        "    models_identical(model, trainer.model)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'eval_loss': 4.751281721837586e-06, 'eval_runtime': 0.0678, 'eval_samples_per_second': 14.758, 'eval_steps_per_second': 14.758, 'epoch': 250.0, 'step': 250}, {'loss': 1.3045, 'learning_rate': 0.0, 'epoch': 500.0, 'step': 500}, {'eval_loss': 4.5980661411704205e-07, 'eval_runtime': 0.017, 'eval_samples_per_second': 58.786, 'eval_steps_per_second': 58.786, 'epoch': 500.0, 'step': 500}, {'train_runtime': 88.2316, 'train_samples_per_second': 5.667, 'train_steps_per_second': 5.667, 'total_flos': 8972163840000.0, 'train_loss': 1.3044609375, 'epoch': 500.0, 'step': 500}]\n"
          ]
        }
      ],
      "source": [
        "print(trainer.state.log_history)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JbudT3jjybFJ"
      },
      "source": [
        "## A. Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgohEHsqyecs",
        "outputId": "e4829c73-5977-448a-f03a-b3f00344baba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n",
            "Generate config GenerationConfig {\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"transformers_version\": \"4.26.0\"\n",
            "}\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[105, 114, 114,  35, 101, 100, 117,   0,   0,   0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0]], device='cuda:0')}\n",
            "tensor([  0, 117, 100, 101,  35, 114, 114, 105, 105, 114], device='cuda:0')\n",
            "tensor([  0, 117, 100, 101,  35, 114, 114, 105, 105, 114], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for batch in trainer.get_train_dataloader():\n",
        "    break\n",
        "batch_without_labels = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "print(batch_without_labels)\n",
        "print(trainer.model.generate(**batch_without_labels, num_beams=2, early_stopping=True, max_length=10)[0])\n",
        "print(model.generate(**batch_without_labels, num_beams=2, early_stopping=True, max_length=10)[0])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "fp16=False : tensor([  0, 117, 100, 101,  35, 114, 114, 105, 105, 114], device='cuda:0')\n",
        "fp16=True : tensor([0, 0, 1], device='cuda:0')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "adjBwP2BkJh1"
      },
      "source": [
        "# B. pytorch-style loop but with some trainer stuff "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPbI75sBkJpb"
      },
      "outputs": [],
      "source": [
        "# create an optimizer\n",
        "trainer.create_optimizer()\n",
        "\n",
        "# get the first (and only) batch\n",
        "for batch in trainer.get_train_dataloader():\n",
        "    break\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "# loop over batches\n",
        "for i in range(epochs):\n",
        "    # get loss\n",
        "    outputs = trainer.model(**batch)\n",
        "    loss = outputs.loss\n",
        "    # gradients and backprop\n",
        "    loss.backward()\n",
        "    trainer.optimizer.step()\n",
        "    trainer.optimizer.zero_grad()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2MuyjNzuDSw"
      },
      "outputs": [],
      "source": [
        "# Check whether models are identical\n",
        "print(\"Untrained model and trained model are the same: \", \n",
        "      models_identical(model_orig, model)\n",
        "      )\n",
        "\n",
        "print(\"Untrained model and trained model are the same: \", \n",
        "      models_identical(model_orig, trainer.model)\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdel\u001b[39;00m model, model_orig\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "del model, model_orig"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

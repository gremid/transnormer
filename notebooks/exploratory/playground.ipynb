{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tomli\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from transnormer.models.train_model import tokenize_datasets\n",
    "from transnormer.evaluation.analysis import get_spans_of_unknown_tokens\n",
    "from transnormer.visualization.formatting import markup_spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs\n",
    "ROOT = os.path.dirname(os.path.dirname(os.path.abspath(''))) # \"../../\"\n",
    "CONFIGFILE = os.path.join(ROOT, \"training_config.toml\")\n",
    "with open(CONFIGFILE, mode=\"rb\") as fp:\n",
    "    CONFIGS = tomli.load(fp)\n",
    "\n",
    "# Fix seeds for reproducibilty\n",
    "random.seed(CONFIGS[\"random_seed\"])\n",
    "np.random.seed(CONFIGS[\"random_seed\"])\n",
    "torch.manual_seed(CONFIGS[\"random_seed\"])\n",
    "\n",
    "# GPU set-up\n",
    "device = torch.device(CONFIGS[\"gpu\"] if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer_input = transformers.AutoTokenizer.from_pretrained(\n",
    "    CONFIGS[\"language_models\"][\"checkpoint_encoder\"]\n",
    ")\n",
    "tokenizer_output = transformers.AutoTokenizer.from_pretrained(\n",
    "    CONFIGS[\"language_models\"][\"checkpoint_decoder\"]\n",
    ")\n",
    "\n",
    "# Load model\n",
    "checkpoint = os.path.join(ROOT, \"models/model/checkpoint-300\") # TODO\n",
    "model = transformers.EncoderDecoderModel.from_pretrained(checkpoint).to(device)\n",
    "\n",
    "\n",
    "s= \"Groß-Fuͤrſten in Finland/ Hertzogen zu Schonen/ Eheſten/ Lieffland/ Carelen/ Bremen/ Vehrden/ Stettin/ Pommern/ der Caſſuben und Wenden/\"\n",
    "inputs = tokenizer_input(s, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to(device)\n",
    "attention_mask = inputs.attention_mask.to(device)\n",
    "\n",
    "outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "del input_ids, attention_mask # free memory\n",
    "output_str = tokenizer_output.batch_decode(outputs, skip_special_tokens=True)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "df_example = pd.DataFrame(data=output_str)\n",
    "display(HTML(df_example.head(1).to_html(escape=False)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0134801864624023"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/byt5-small\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")\n",
    "\n",
    "model_inputs = tokenizer(\n",
    "    [\"Groß-Fuͤrſten in Finland/ Hertzogen zu Schonen/ Eheſten/ Lieffland/ Carelen/ Bremen/ Vehrden/ Stettin/ Pommern/ der Caſſuben und Wenden/\"], padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "labels_dict = tokenizer(\n",
    "    [\"Groß-Fürsten in Finnland/ Herzogs zu Schonen/ Ehesten/ Livland/ Carelen/ Bremen/ Vehrden/ Stettin/ Pommern/ der Kasuben und Wenden/\"], padding=\"longest\", return_tensors=\"pt\"\n",
    ")\n",
    "labels = labels_dict.input_ids\n",
    "\n",
    "loss = model(**model_inputs, labels=labels).loss\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = model.generate(**model_inputs, max_length=100)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', 'en/ Stettin/ Pommern/ Pommern/ Pommern/ Pommern/ Pommern/ Pommern/ Pommern/ Pommern/ Pommern/ Pomm']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Now we need to split on the sentinel tokens, let's write a short loop for this\n",
    "\n",
    "output_ids_list = []\n",
    "\n",
    "start_token = 0\n",
    "\n",
    "sentinel_token = 258\n",
    "\n",
    "while sentinel_token in output_ids:\n",
    "    split_idx = output_ids.index(sentinel_token)\n",
    "    output_ids_list.append(output_ids[start_token:split_idx])\n",
    "    start_token = split_idx\n",
    "    sentinel_token -= 1\n",
    "\n",
    "output_ids_list.append(output_ids[start_token:])\n",
    "output_string = tokenizer.batch_decode(output_ids_list)\n",
    "print(output_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.T5ForConditionalGeneration.from_pretrained(\"../../tests/testdata/saved-tmp/checkpoint-600\").to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ids = model.generate(**model_inputs, max_length=100)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "chr() arg not in range(0x110000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m([\u001b[39mchr\u001b[39m(output_id \u001b[39m-\u001b[39m \u001b[39m3\u001b[39m) \u001b[39mfor\u001b[39;00m output_id \u001b[39min\u001b[39;00m output_ids])\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(output_ids)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(chr(101))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m([\u001b[39mchr\u001b[39;49m(output_id \u001b[39m-\u001b[39;49m \u001b[39m3\u001b[39;49m) \u001b[39mfor\u001b[39;00m output_id \u001b[39min\u001b[39;00m output_ids])\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(output_ids)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(chr(101))\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: chr() arg not in range(0x110000)"
     ]
    }
   ],
   "source": [
    "for output_id in output_ids:\n",
    "    try:    \n",
    "        print(chr(output_id - 3), end=\"\")\n",
    "    except ValueError:\n",
    "        print(output_id)\n",
    "\n",
    "print([for output_id in output_ids])\n",
    "# print(output_ids)\n",
    "# print(chr(101))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-venv-transnormer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "78c4187baaf57098bb0b3703ce789bfcb46625a5d8666ee97b80d797f8c6f211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

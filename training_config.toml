# -*- coding = utf-8 -*-

# Select GPU
gpu = "cuda:0"  # do `export CUDA_VISIBLE_DEVICES=1` when starting environment

# Random seed (fix for reproducibility)
random_seed = 42

# Output directory
# outdir = "./models/model"

# Data
[data]
paths_train = [
    "/home/bracke/data/dtaec/jsonl/v03/aehrm-split/dtaec-train.jsonl",
    # "data/interim/dtak-v03-1600-1699/dtak-v03-1600-1699-train.jsonl",
    # "data/interim/dtak-v03-1700-1799/dtak-v03-1700-1799-train.jsonl",
    # "data/interim/dtak-v03-1800-1899/dtak-v03-1800-1899-train.jsonl",
]

paths_validation = [
    "/home/bracke/data/dtaec/jsonl/v03/aehrm-split/dtaec-dev.jsonl",
    # "data/interim/dtak-v03-1600-1699/dtak-v03-1600-1699-validation.jsonl",
    # "data/interim/dtak-v03-1700-1799/dtak-v03-1700-1799-validation.jsonl",
    # "data/interim/dtak-v03-1800-1899/dtak-v03-1800-1899-validation.jsonl",
]

paths_test = [
    "/home/bracke/data/dtaec/jsonl/v03/aehrm-split/dtaec-test.jsonl",
    # "data/interim/dtak-v03-1600-1699/dtak-v03-1600-1699-test.jsonl",
    # "data/interim/dtak-v03-1700-1799/dtak-v03-1700-1799-test.jsonl",
    # "data/interim/dtak-v03-1800-1899/dtak-v03-1800-1899-test.jsonl",
]
n_examples_train = [
    130_000,  # all
    # 10_000,
    # 1_000_000_000,
]
n_examples_validation = [
    50_000,  # all
    # 1_000_000_000,
    # 1_000_000_000,
]
# not used
n_examples_test = [
    1,
    # 1_000_000_000,
    # 1_000_000_000,
]

[tokenizer]
tokenizer = "google/byt5-small"
padding = "longest"
min_length_input = 0
max_length_input = 512
# max_length_output = 512
# input_transliterator = "Transliterator1"

# Base model(s)
[language_models]
# checkpoint_encoder_decoder = "google/byt5-small"
checkpoint_encoder_decoder = "/home/bracke/code/transnormer/models/models_2024-08-15"

[training_hyperparams]
batch_size = 8
epochs = 10
learning_rate = 0.001
fp16 = false
save_strategy = "epoch"
eval_strategy = "steps"
logging_strategy = "steps"
# dummy values for eval_steps and logging_steps will be ignored
# instead evaluates/logs twice per epoch (via CustomCallback)
eval_steps = 1000000
logging_steps = 100000
# outdir_path = "./models/model"

# Parameters for beam search decoding
[beam_search_decoding]
no_repeat_ngram_size = 0
early_stopping = false
length_penalty = 2.0
num_beams = 4

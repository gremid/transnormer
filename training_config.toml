# -*- coding = utf-8 -*-

# Select GPU
gpu = "cuda:0" # when you did `export CUDA_VISIBLE_DEVICES=1` first

# Random seed (fix for reproducibility)
random_seed = 42

# Data subsets sizes
[subset_sizes]
train = 10
validation = 10
test = 1

# [tokenizer]
# path = "resources/tokenizer-wp-dta1600-1899"
# padding = true
# truncation = true
# max_length = 256 

# Model that is retrained
[language_models]
checkpoint_encoder = "dbmdz/bert-base-historic-multilingual-cased"
checkpoint_decoder = "bert-base-multilingual-cased"

[training_hyperparams]
batch_size = 32 
# report_avg_loss_after_n_batches = 100
epochs = 10
# learning_rate = 0.001
# momentum = 0.9





